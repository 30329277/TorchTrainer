# TorchTrainer
code trains an object detection model using Faster R-CNN with a custom dataset. It parses XML annotations, applies transformations, and supports loading pre-trained weights. The model is fine-tuned over multiple epochs with a learning rate scheduler and outputs progress.

# README  

## é¡¹ç›®ç®€ä»‹ / Project Overview  
è¯¥é¡¹ç›®åŒ…å«ä¸‰ä¸ªåŠŸèƒ½æ¨¡å—ï¼š  
1. **è§†é¢‘ç›®æ ‡æ£€æµ‹**ï¼šåŸºäº Faster R-CNN æ¨¡å‹ï¼Œæ£€æµ‹è§†é¢‘å¸§ä¸­çš„ç‰¹å®šç›®æ ‡ï¼Œå¹¶ä¿å­˜åŒ…å«æ£€æµ‹ç»“æœçš„å›¾åƒã€‚  
2. **ç›®æ ‡æ£€æµ‹æ¨¡å‹è®­ç»ƒ**ï¼šåˆ©ç”¨è‡ªå®šä¹‰æ•°æ®é›†ï¼ˆå›¾åƒåŠå…¶å¯¹åº”çš„ XML æ ‡æ³¨æ–‡ä»¶ï¼‰è®­ç»ƒç›®æ ‡æ£€æµ‹æ¨¡å‹ã€‚  
3. **è§†é¢‘å¸§æå–**ï¼šä»è§†é¢‘ä¸­æŒ‰æŒ‡å®šæ—¶é—´é—´éš”æå–å¸§å¹¶ä¿å­˜ä¸ºå›¾ç‰‡ã€‚  

This project includes three modules:  
1. **Object Detection in Videos**: Detect objects in video frames using a Faster R-CNN model and save the annotated frames.  
2. **Object Detection Model Training**: Train an object detection model with a custom dataset (images and XML annotations).  
3. **Video Frame Extraction**: Extract video frames at specified intervals and save them as images.  

---

## ç¯å¢ƒä¾èµ– / Environment Requirements  
- Python 3.8+  
- å¿…éœ€åº“ / Required Libraries:  
  - `torch`, `torchvision`  
  - `opencv-python`  
  - `tqdm`  

---

## ä½¿ç”¨è¯´æ˜ / Usage  

### 1. è§†é¢‘ç›®æ ‡æ£€æµ‹ / Object Detection in Videos  
**æ–‡ä»¶**: `main.py`  
ä¿®æ”¹ `main()` ä¸­çš„è§†é¢‘è·¯å¾„ `video_path`ï¼Œè¿è¡Œè„šæœ¬å³å¯ã€‚  

**File**: `detect_object.py`  
Update the video path (`video_path`) in the `main()` function and run the script.  

### 2. æ¨¡å‹è®­ç»ƒ / Model Training  
**æ–‡ä»¶**: `train_model.py`  
å°†æ•°æ®é›†æ”¾åœ¨ `data_dir` è·¯å¾„ä¸‹ï¼Œç¡®ä¿åŒ…å«å›¾åƒå’Œ XML æ ‡æ³¨æ–‡ä»¶ã€‚è¿è¡Œè„šæœ¬è¿›è¡Œæ¨¡å‹è®­ç»ƒï¼Œç»“æœä¼šä¿å­˜ä¸º `objectA_detector_model.pth`ã€‚  

**File**: `train_model.py`  
Place your dataset in the `data_dir` directory, ensuring it contains images and XML annotation files. Run the script to train the model, and the result will be saved as `objectA_detector_model.pth`.  

### 3. è§†é¢‘å¸§æå– / Video Frame Extraction  
**æ–‡ä»¶**: `capture_frames.py`  
ä¿®æ”¹è§†é¢‘è·¯å¾„ `video_path` å’Œè¾“å‡ºè·¯å¾„ `output_dir`ï¼Œè¿è¡Œè„šæœ¬å³å¯ã€‚  

**File**: `capture_frames.py`  
Update the video path (`video_path`) and output directory (`output_dir`), then run the script.  

---

## è¾“å‡ºç¤ºä¾‹ / Example Outputs  
1. **æ£€æµ‹åçš„å¸§ / Detected Frames**: å¸§ä¸­ç»˜åˆ¶äº†ç›®æ ‡çš„è¾¹ç•Œæ¡†åŠå…¶ç½®ä¿¡åº¦åˆ†æ•°ã€‚  
2. **è®­ç»ƒå®Œæˆçš„æ¨¡å‹ / Trained Model**: æ–‡ä»¶åä¸º `objectA_detector_model.pth`ã€‚  
3. **æå–çš„å¸§ / Extracted Frames**: æŒ‰æŒ‡å®šé—´éš”ä¿å­˜çš„å›¾ç‰‡æ–‡ä»¶ã€‚  

1. **Detected Frames**: Frames with bounding boxes and confidence scores for detected objects.  
2. **Trained Model**: Saved as `objectA_detector_model.pth`.  
3. **Extracted Frames**: Images saved at specified intervals.  

---

## æ³¨æ„äº‹é¡¹ / Notes  
1. ç¡®ä¿è§†é¢‘æ–‡ä»¶è·¯å¾„å’Œè¾“å‡ºç›®å½•æ­£ç¡®ã€‚  
2. æ•°æ®é›†åº”åŒ…å«æ ‡å‡† Pascal VOC æ ¼å¼çš„ XML æ–‡ä»¶ã€‚  
3. è®­ç»ƒæ—¶å»ºè®®ä½¿ç”¨ GPU æé«˜é€Ÿåº¦ã€‚  

1. Ensure correct paths for video files and output directories.  
2. The dataset should include XML files in standard Pascal VOC format.  
3. Use a GPU for faster training.  

Enjoy coding! ğŸ˜Š  

